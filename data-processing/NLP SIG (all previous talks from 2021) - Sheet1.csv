Date,Presenter,Event Name,Type of Session,Zoom Link,Room,Abstract,Bio for Speaker,Paper Links
29/01/2025,,,free for booking,,,,,
22/01/2025,Tao Wang,Temporal Reasoning in Clinical Text: Building Medical Timelines with LLMs,seminar,,,"Temporal information in electronic health records (EHRs) is often vague, fragmented, and inconsistently documented, making timeline reconstruction challenging. This talk introduces a benchmark dataset and a large language model (LLM)–based framework for automating temporal inference from clinical text. We explore enhanced prompting strategies that combine Chain-of-Thought reasoning, temporal markup, and layout cues to improve event-time alignment. Preliminary findings suggest that model performance varies across strategies for both global and single-event queries. We conclude with implications for treatment pathway analysis, temporal phenotyping, and real-world deployment. ","Dr. Tao Wang is a Research Fellow in Health Text Analytics and Data Science in the Department of Biostatistics & Health Informatics at King’s College London. His research focuses on developing advanced AI methods to extract, integrate, and reason over complex health data. His interests include: Natural Language Processing (NLP), Health Data Science, Multimodal Learning, Knowledge Graphs and Reasoning, and Clinical Decision Support Systems. 
",
27/11/2025,Elena Kochkina,TBA,seminar,,,,,
13/11/2025,Joanna Kuc,TBA,seminar,,,,,
30/10/2025,Jabez Magomere,When Claims Evolve: Evaluating and Enhancing the Robustness of Embedding Models Against Misinformation Edits,seminar,https://teams.microsoft.com/l/meetup-join/19%3ameeting_ZDg2YWYyMWMtMWI5ZS00ZWM1LWFkZmEtNDM4NzU3MDdjNWM3%40thread.v2/0?context=%7b%22Tid%22%3a%22569df091-b013-40e3-86ee-bd9cb9e25814%22%2c%22Oid%22%3a%2282b17dff-3f22-4616-9cf5-35ed68dd29d4%22%7d ,Ada Lovelace,"In this talk, I will explore the challenge of evaluating the robustness of embedding models in real-world applications where users may introduce subtle edits to text, such typos, negations, dialect shifts, and entity replacements. This issue is particularly prevalent in misinformation contexts, where claims evolve as they spread online, yet embedding models are typically trained and tested on clean, static datasets that fail to capture real-world variability. I will discuss why measuring robustness in these dynamic settings is difficult and how conventional benchmarks like MTEB overlook linguistic diversity in the wild. I will then introduce our framework that uses LLMs as both perturbers and verifiers to generate valid, natural claim variations, enabling systematic robustness evaluation of embedding models multi-stage retrieval pipelines (first-stage retrieval and reranking). Finally, I will present results from a large-scale comparison of BERT, T5, and LLM-distilled models, and outline mitigation approaches to improve robustness in noisy, evolving real-world text.
","Jabez Magomere is a Rhodes Scholar and PhD student at the University of Oxford, where he studies ways to improve the factuality and grounding of large language models. His broader research explores how AI systems can reason across diverse languages and cultural contexts, including work on linguistic reasoning in low-resource and extinct languages, synthetic data generation for specialized domains, and evaluating cultural bias in text-to-image systems. He has also applied his research in industry through internships at Google DeepMind and JPMorgan Chase.",
23/10/2025,Fawzia Zehra Kara-Isitt,Malicious Markovs - Hate Speech Monitoring through Probabilistic Modelling,seminar,,,"This talk predicts my thesis, which investigates sentiment classification and analysis methodologies for detecting online harm in social media content, with the objective of identifying and predicting dangerous viral text trends whilst exploring the deployment of automated counter-speech mechanisms to mitigate toxicity. The proliferation of social media platforms has generated an immense, continuously expanding data stream where users, exploiting perceived anonymity and free speech protections, can inflict significant harm. Current automated moderation systems demonstrate notable inadequacies in addressing toxic behaviour, occasionally resulting in severe consequences including the propagation of violent extremist content, cyberbullying, and suicide ideation.

This research aims to identify and predict harmful speech within subjective topical domains through novel methodological frameworks and algorithmic approaches, specifically targeting early detection before contentious topics escalate into widespread weaponised trends. The methodology employs mathematical algorithms to quantify and analyse captured content, facilitating predictive modelling for hate speech emergence patterns.

The study evaluates multiple computational tools, processes, and methodological approaches through comparative analysis. Various techniques for categorising social media sentiment are assessed across dimensions including ""Toxicity,"" ""Aggression,"" ""Attacking,"" and ""Neutral"" classifications, utilising existing open-source sentiment analysis tools and historical Wikipedia datasets. Machine learning and data science techniques are systematically applied to enhance sentiment scoring accuracy, with comprehensive evaluation of tool reliability in sentiment capture tasks.

Temporal analysis leverages original Universal Coordinated Time (UTC) timestamps as reference points for forecasting hate speech trends through stable state analysis, probability distributions, Markov Chains, stable state similarities, and optimisation techniques to identify emergent harmful viral patterns within specific topical domains. This comprehensive multi-methodological approach to detecting and predicting online hate speech patterns through complementary sentiment analysis procedures contributed to a publication at ECML PKDD SoGood 2022, with four additional papers currently in development.

The predictive intelligence acquired through these techniques was subsequently integrated with generative tools to synthesise synthetic toxic conversations based on original seed content, enabling proactive countermeasure development as the next phase towards mitigating hate speech in pursuit of ""#EndOnlineHarm.""

Keywords - Classification; Counter-Speech; Detection; Generative AI; Heuristics; Jaccard Similarities; Large Language Models; Machine Learning; Markov Chains; Online Harm; Sentiment Analysis; Time Series Analysis.
","Fuzzy Kara-Isitt is a doctoral researcher at Brunel University's Intelligent Data Analysis group, where she's on a mission to make the internet a kinder place—one algorithm at a time. Her research focuses on detecting and mitigating online toxicity using sentiment analysis, because apparently someone needs to teach machines the difference between passionate debate and digital warfare.

A multilingual advocate who volunteers as a mental health first aider and participates in anti-hate hackathons, Fuzzyhas lived in four culturally different countries and believes the best way to solve global problems is to bring together diverse perspectives, a good sense of humour, and really robust error handling.

Currently seeking opportunities to continue her work in AI for social good, within research as a fellow in academia or industry, Fuzzy is particularly interested in bridging the gap between academic research and real-world applications and working towards advocacy and protection of the vulnerable online to make the digital world safer and simply kinder for everyone.",
25/09/2025,Mahmud Akter,Ethics in NLP Security Research (Continued,journal club,,,"We're continuing our casual journal club on ""Ethics in NLP Research"" with our second paper discussion.
Mahmud Akter (QMUL) has kindly volunteered to lead the discussion on:
    ""NLP Security and Ethics, in the Wild"" by Lent et al. (2025), presented at TACL
Brief Paper Summary: This work examines how NLP security research often operates in an ethical ""gray zone,"" lacking established frameworks from cybersecurity ethics like harm minimization, coordinated vulnerability disclosure, and responsible public disclosure. The authors surveyed 80 NLP security papers and found that many fail to adopt cybersecurity's ethical best practices, potentially benefiting attackers more than defenders.
This paper connects well with our ongoing theme of research ethics in the NLP community and should spark interesting discussions about responsible disclosure, potential misuse, and cross-disciplinary ethical frameworks.",,
11/09/2025,Samuel Mensah,"Mitigating Entity Bias in ""Large"" Language Models: A Focus on Relation Extraction",seminar,,,"In this talk, we will highlight our recent efforts to improve relation extraction by addressing the critical challenge of mitigating entity bias in ""large"" language models.
 
We will begin by discussing the importance of relation extraction in various domains, with a specific focus on finance. We will examine the current performance of using ""large"" language models, including both encoder-decoder and decoder-only architectures, and identify the limitations of these approaches, particularly their tendency to rely excessively on entities, resulting in poor generalization. We will then introduce our novel approach using the Variational Information Bottleneck (VIB) framework, which compresses entity-specific information while preserving task-relevant features. This method achieves state-of-the-art performance on relation extraction datasets across general, financial, and biomedical domains, in both in-domain and out-of-domain settings. Finally, we will discuss the insights gained from our approach, emphasizing its interpretable methodology and exploring future research directions to further enhance relation extraction techniques.","Dr Samuel Mensah is a Senior Research Scientist at JPMorgan Chase & Co., with over 10 years of experience in Natural Language Processing (NLP) and Machine Learning. Previously, he was a Postdoctoral Researcher at the University of Sheffield's NLP Group and was affiliated with the Beijing Advanced Innovation Centre for Big Data and Brain Computing in Beijing, China. Samuel also served as a Senior NLP Consultant at Safe Sign Technologies (currently acquired by Thomson Reuters), where he assisted in developing the world's best proprietary legal LLM. He holds a PhD in Computer Software and Theory from Beihang University in Beijing, China. Samuel possesses a unique blend of academic research expertise and experience, contributing to the advancement of AI solutions across various domains.",
28/08/2025,Sebastian Löbbers,Ethics in NLP Research,journal club,,,"This is an informal reading group where we explore interesting papers together. We'll be discussing two papers that caught our attention:

""Generative Ghosts: Anticipating Benefits and Risks of AI Afterlives"" - exploring the implications of AI agents representing deceased individuals",,Generative Ghosts: Anticipating Benefits and Risks of AI Afterlives
14/08/2025,Mahmud Akter & Xingwei Tan,Advancing LLM Reasoning - From Claim Verification to Symbolic Guidance,seminar,,Ada Lovelace,"The session will explore the current state and future directions of reasoning capabilities in large language models, covering both the assessment of reasoning through claim verification and novel approaches to enhance logical reasoning through symbolic methods.
Abstract 1: Although LLMs have shown great performance on Mathematics and Coding related reasoning tasks, the reasoning capabilities of LLMs regarding other forms of reasoning are still an open problem. Here, we examine the issue of reasoning from the perspective of claim verification. We propose a framework designed to break down any claim paired with evidence into atomic reasoning types that are necessary for verification. We use this framework to create RECV, the first claim verification benchmark, incorporating real-world claims, to assess the deductive and abductive reasoning capabilities of LLMs. The benchmark comprises of three datasets, covering reasoning problems of increasing complexity. We evaluate three state-of-the-art proprietary LLMs under multiple prompt settings. Our results show that while LLMs can address deductive reasoning problems, they consistently fail in cases of abductive reasoning. Moreover, we observe that enhancing LLMs with rationale generation is not always beneficial. Nonetheless, we find that generated rationales are semantically similar to those provided by humans, especially in deductive reasoning cases.
Abstract 2: Large language models (LLMs) have shown promising performance in mathematical and logical reasoning benchmarks. However, recent studies have pointed to memorization, rather than generalization, as one of the leading causes for such performance. LLMs, in fact, are susceptible to content variations, demonstrating a lack of robust symbolic abstractions supporting their reasoning process. To improve reliability, many attempts have been made to combine LLMs with symbolic methods. Nevertheless, existing approaches fail to effectively leverage symbolic representations due to the challenges involved in developing reliable and scalable verification mechanisms. In this paper, we propose to overcome such limitations by generating symbolic reasoning trajectories and select the high-quality ones using a process reward model automatically tuned based on Monte Carlo estimation. The trajectories are then employed via fine-tuning methods to improve logical reasoning and generalization. Our results on logical reasoning benchmarks such as FOLIO and LogicAsker show the effectiveness of the proposed method with large gains on frontier and open-weight models. Moreover, additional experiments on claim verification reveal that fine-tuning on the generated symbolic reasoning trajectories enhances out-of-domain generalizability, suggesting the potential impact of symbolically-guided process supervision in alleviating the effect of memorization on LLM reasoning.
","Mahmud Elahi Akhter is a Research Assistant at Maria Liakata NLP lab at the School of Electronic Engineering and Computer Science at Queen Mary University of London, UK. In 2020, He earned his B.Sc. degree in computer science and engineering from North South University, Bangladesh. Before joining QMUL, he was a Research Assistant at the Department of Electrical and Computer Engineering, North South University, Department of Electrical and Electronic Engineering, University of Dhaka, and the Institute of Statistical Research and Training, University of Dhaka. Previously, he worked on multilingual language modeling, internal representation learning, biomedical object detection, inverse and surrogate modeling and statistical modeling of malnutrition and poverty. His current work focuses on explainability of PLM's and LLM's for rumour and claim veracity.
Xingwei Tan is a research associate at Sheffield NLP working with Prof. Nikos Aletras. Before that, he was pursuing his PhD in the Department of Computer Science, University of Warwick, supervised by Prof. Yulan He and Dr. Gabriele Pergola. He received his MSc. from South China University of Technology in 2020 and his bachelor's degree from Sun Yat-Sen University in 2017. His research interests span sentiment analysis, event understanding, information extraction, and reasoning with large language models.",https://aclanthology.org/2025.findings-acl.1059.pdf;  https://arxiv.org/pdf/2505.20415? 
24/07/2025,Joseph Boyle,Building Useful Agents,seminar,,,,,
10/07/2025,Jialin Yu,Attuned to Change: Causal Fine-Tuning under Latent-Confounded Shifts,seminar,,,,,
26/06/2025,Chiara Di Bonaventura,Hatevolution: What Static Benchmarks Don’t Tell Us,seminar,,,,,
29/05/2025,,RAG to Reasoning: Safety and Verification Frontiers in LLM Research,journal club,,,,,
22/05/2025,Cohere researchers: Shivalika Singh and Yiyang Nan,The Leaderboard Illusion,seminar,,,,,
08/05/2025,Shuang Ao,"Trustworthy Adaptation of LLMs: Uncertainty, Safety, and Cross-Modal Alignment",seminar,,,,,
01/05/2025,,Cross-lingual Transfer Techniques,journal club,,,,,
10/04/2025,Michael Schlichtkrull,Pretraining Large Language Models: A Deepdive,seminar,,,,,
03/04/2025,Yuxiang Zhou,Understanding the Capabilities of (Large) Language Models and Their Real-World Applications,seminar,,,,,
27/03/2025,Jonas Geiping,What's so interesting about models with recurrent depth?,seminar,,,,,
13/03/2025,,NLP Applications in Mental Health and Healthcare,journal club,,,,,
27/02/2025,Aryo Gema,DeCoRe: Decoding by Contrasting Retrieval Heads to Mitigate Hallucinations,seminar,,,,,
13/02/2025,Ibraheem Muhammad Moosa,MT-Ranker: Reference-free machine translation evaluation by inter-system ranking,seminar,,,,,
06/02/2025,Sriyash Poddar,Personalizing Reinforcement Learning from Human Feedback with Variational Preference Learning,seminar,,,,,
30/01/25,Michael Schlichtkrull,"""DeepSeek-R1"" Reinforcement Learning for Open Source LLMs",seminar,,,,,
23/01/25,,Reasoning in LLMs,journal club,,,,,
04/07/2024, ,Reasoning in Large Language Models,journal club,,,,,
27/06/2024, ,LLMs for Code Generation,journal club,,,,,
24/06/2024, ,Large Language Models,journal club,,,,,
13/06/2024, ,Large Language Models,journal club,,,,,
06/06/2024, ,Large Language Models,journal club,,,,,
30/05/2024, ,Reasoning in Large Language Models,journal club,,,,,
09/05/2024, ,Reasoning in Large Language Models,journal club,,,,,
02/05/2024, ,Reasoning in Large Language Models,journal club,,,,,
25/04/2024, ,Reasoning in Large Language Models,journal club,,,,,
11/04/2024, ,Interpretability in Large Language Models,journal club,,,,,
04/04/2024, ,Retrieval Augmented Generation (RAG) for LLMs,journal club,,,,,
28/03/2024,"Prof. Ann John (Swansea)
Prof. Dana Atzil-Slonim (Bar-Ilan University)
Prof. Eiman Kanjo (Nottingham Trent/Imperial)
Prof. Joseph Hayes (UCL)
Prof. Philip Resnik (University of Maryland)
Prof. Robert Stewart (King's College London)
Dr. Valentin Tablan (IESO)","AI UK Fringe event, ""AI for Mental Health Monitoring"", jointly organised by the ""Natural Language Processing"" and ""Data Science for Mental Health"" Turing Interest Groups. ",conference,,,,,
07/03/2024, ,Hallucinations in Large Language Models,journal club,,,,,
29/02/024, ,Evaluation with Large Language Models,journal club,,,,,
22/02/2024, ,Annotation Capabilities of Large Language Models,journal club,,,,,
08/02/2024, ,Neural Theory of Mind - Capabilities of Large Language Models,journal club,,,,,
01/02/2024, ,Capabilities of Large Language Models,journal club,,,,,
25/01/2024, ,Taking Automated Fact-checking to the Real World,journal club,,,,,
11/01/2024, ,Paper Skimming,journal club,,,,,
14/12/2023, ,Large Language Models are Few-Shot Training Example Generators: A Case Study in Fallacy Recognition,journal club,,,,,
30/11/2023, ,Are Large Language Models Temporally Grounded?,journal club,,,,,
23/11/2023, ,Parameter Efficient Fine-tuning of LLMs,journal club,,,,,
09/11/2023, ,Large Language Models,journal club,,,,,
01/11/2023,Mahmud Elahi Akhter,Does Transliteration Help Multilingual Language Modeling?,seminar,,,,,
26/10/2023,Jose Camacho-Collados,"NLP and Social media: Language Modelling, Benchmarking and Temporal Challenges",seminar,,,,,
12/10/2023, ,Rumour Verification / Fact Checking,journal club,,,,,
05/10/2023, ,Summarisation,journal club,,,,,
21.09.23,Talia Tseriotou,“Alternative approaches for modeling positional encodings in transformers” - Reading Group,journal club,,,,,
07.09.23,"Adam Tsakalidis
&
Anthony Hills",“ACL 2023” - Reading Group,journal club,,,,,
24.08.23,Talia Tseriotou,“ACL 2023” - Reading Group,journal club,,,,,
03.08.23,,“ChatGPT and LLMs” - Reading Group,journal club,,,,,
27.07.23,"Joseph Spartacus Boyle
&
Jenny Chim",“Knowledge Injection” - Reading Group,journal club,,,,,
29.06.23,,Paper Skimming,journal club,,,,,
08.06.23,Jenny Chim,Hands-on Tutorial for Prompt Engineering,workshop,,,,,
01.06.23,,Paper Skimming,journal club,,,,,
27.04.23,Federico Ruggeri,Combining Transformers with Natural Language Explanations,seminar,,,,,
06.04.23,,Paper Skimming,journal club,,,,,
30.03.23,Luis Espinosa-Anke,NLP for Intelligence: Tweet and News Analysis for Data-Driven Decision Making,seminar,,,,,
23.03.23,"MA, Jing",Social Assisted Rumor Detection and Fake News Detection,seminar,,,,,
09.03.23,,Paper Skimming on Long Document Transformers,journal club,,,,,
02.03.23,,Paper Skimming on Long Document Transformers,journal club,,,,,
23.02.23,,Paper Skimming,journal club,,,,,
09.02.23,,Paper Skimming,journal club,,,,,
02.02.23,Zixiu Wu,NLP-Based Real-Time Assistance to Human Therapist,seminar,,,,,
26.01.23,Georgi Karadzhov,DEliBots - Deliberation Enhancing Bots,seminar,,,,,
12.01.23,,EMNLP Paper Skimming Session,journal club,,,,,
01.12.22,Everyone,Paper Skimming Session,journal club,,,,,
24.11.22,Danny To Eun Kim,Can dialogue systems have a theory-of-mind?,seminar,,,,,
10.11.22,Everyone,Paper Skimming,journal club,,,,,
03.11.22,Elena Kochkina,Evaluating the Generalisability of Neural Rumor Verification Models,seminar,,,,,
27.10.22,Everyone,Paper Skimming,journal club,,,,,
13.10.22,,Paper Skimming,journal club,,,,,
04.10.22,Iryana Gurevych,Detect – Verify – Communicate: Combating Misinformation with More Realistic NLP,seminar,,,,,
25/11/2022,,"""PhD Enrichment Scheme"" Introduction to the teams",other,,,,,
24/11/2022,Danny To Eun Kim,Can dialogue systems have a theory-of-mind? - Danny To Eun Kim,seminar,,,,,
10/11/2022,,Paper Skimming,journal club,,,,,
3/11/2022,Elena Kochkina,"""Evaluating the Generalisability of Neural Rumor Verification Models"" with Elena Kochkina",seminar,,,,,
27/10/2022,,Paper Skimming,journal club,,,,,
4/10/2022,Iryana Gurevych,"""Detect – Verify – Communicate: Combating Misinformation with More Realistic NLP"" with Iryana Gurevych",seminar,,,,,
9/29/2022,Hao Ni,"""Path Development Network with Finite-Dimensional Lie Group"" with Hao Ni",seminar,,,,,
9/27/2022,,Paper Skimming,journal club,,,,,
9/8/2022,Iman Bilal,"""Template-based Abstractive Microblog Opinion Summarisation"" with Iman Bilal",seminar,,,,,
9/1/2022,,Paper Skimming,journal club,,,,,
8/4/2022,Ramit Sawhney,"""User Modeling on Social Media: Privacy, Ethics, and Mental Health"" with Ramit Sawhney",seminar,,,,,
7/28/2022,Krishnapriya Vishnubhotla and Saif Mohammad,"""Tweet Emotion Dynamics: Emotion Word Usage in Tweets from US and Canada"" and ""Ethics Sheets for AI"" with Krishnapriya Vishnubhotla and Saif Mohammad",journal club,,,,,
7/20/2022,Anthony Hills,"""Neural Spatio-temporal Point Processes"" with Anthony Hills",seminar,,,,,
7/14/2022,,Paper Skimming (NAACL),journal club,,,,,
7/7/2022,,Paper Skimming (NAACL),journal club,,,,,
6/30/2022,Matt Maufe,"""Learning from ACL 2022 - Building Better Models"" with Matt Maufe",seminar,,,,,
6/9/2022,,Paper Skimming,journal club,,,,,
5/12/2022,,Paper Skimming,journal club,,,,,
5/5/2022,,Paper Skimming,journal club,,,,,
4/22/2022,Ramit Sawhney,"""Modeling User Context for Mental Health Assessment on Social Media"" with Ramit Sawhney",journal club,,,,,
4/14/2022,Giannis Karamanolakis,"""Weakly-supervised learning in NLP"" with Giannis Karamanolakis",journal club,,,,,
3/31/2022,,Paper Skimming,journal club,,,,,
3/31/2022,Iman Bilal,"""Evaluation of Thematic Coherence in Microblogs"" with Iman Bilal",journal club,,,,,
3/10/2022,,Paper Skimming,journal club,,,,,
3/3/2022,,Paper Skimming,journal club,,,,,
2/24/2022,James Bishop,"""Hands-on Session: Zero shot learning for NLI"" with James Bishop",workshop,,,,,
11/27/2022,Kaspar Beelen,"""Hands-on Session: Flair"" with Kaspar Beelen",workshop,,,,,
2/3/2022,Rafael Mestre,"""Multimodal analysis of political debates with text, audio and video: from argumentation to sentiment analysis"" with Rafael Mestre",seminar,,,,,
1/27/2022,,Paper Skimming,journal club,,,,,
1/13/2022,,"""Topic-Driven Sentiment Analysis"" with Yulan He",seminar,,,,,
1/6/2022,,Paper Skimming,journal club,,,,,
12/12/2021,Yulan He,Hands-on Session: Baleen 3 and Annot8,workshop,,,,,
12/2/2021,,Paper Skimming Session,journal club,,,,,
11/25/2021,,"Paper Skimming Session",journal club,,,,,
10/28/2021,,"Paper Skimming Session",journal club,,,,,
10/14/2021,Peifeng Wang,"""Incorporating Structured Knowledge for Machine Commonsense Reasoning"" with Peifeng Wang",seminar,,,,,
10/7/2021,,Paper Skimming Session,journal club,,,,,
9/30/2021,Harish Tayyar Madabushi,"""AStitchInLanguageModels: Dataset and Methods for the Exploration of Idiomaticity in Pre-Trained Language Models SemEval 2022 Task 2 Multilingual Idiomaticity Detection and Sentence Embedding"" with Harish Tayyar Madabushi",seminar,,,,,
9/23/2021,,Paper Skimming Session ,journal club,,,,,
7/22/2021,,Paper Skimming Session ,journal club,,,,,
7/8/2021,,Paper Skimming Session ,journal club,,,,,
7/1/2021,,Paper Skimming Session ,journal club,,,,,
6/24/2021,,Paper Skimming Session ,journal club,,,,,
6/3/2021,Avijit Thawani,"""Numbers in NLP"" with Avijit Thawani",seminar,,,,,
5/27/2021,Stuart Middleton,"""SafeSpacesNLP"" with Stuart Middleton",seminar,,,,,
5/13/2021,Saif Mohammad,"""Ethics Sheets for AI Tasks and a Case Study for Automatic Emotion Recognition"" with Saif Mohammad",seminar,,,,,
5/6/2021,Alexander Mikhalev,"""Open Source project for NLP research collaboration: NLP meets VR/AR"" with Alexander Mikhalev",seminar,,,,,
4/29/2021,Mimie Liotsiou,"""The influence of online (mis)information: prediction, explanation, causality"" with Mimie Liotsiou",seminar,,,,,
4/8/2021,James Ravenscroft and Gabriele Pergola,"""CD2CR: Coreference Resolution Across Documents and Domains"" and ""Boosting Low-Resource Biomedical QA via Entity-Aware Masking Strategies"" with James Ravenscroft and Gabriele Pergola",seminar,,,,,
3/25/2021,Bill Lampos,"""Tracking COVID-19 using online search"" with Bill Lampos",seminar,,,,,
3/23/2021,,AIUK2021 booth presentation,conference,,,,,
3/11/2021,Radu Voit,"""Deep Reinforcement Learning with a Combinatorial Action Space for Predicting Popular Re ddit Threads"" with Radu Voit",seminar,,,,,
3/4/2021,,Paper Skimming Session,journal club,,,,,
2/25/2021,Paul Rottger,"""HATECHECK: Functional Tests for Hate Speech Detection Models"" with Paul Rottger",seminar,,,,,
11/2/2021,James Ravenscroft,"""Rationalising Neural Predictions"" with James Ravenscroft",seminar,,,,,
10/29/2021,,Paper Skimming Session,journal club,,,,,
10/21/2021,Dimitris Gkoumas,"""Quantum cognitively motivated multimodal representation learning for human language analysis"" with Dimitris Gkoumas",seminar,,,,,